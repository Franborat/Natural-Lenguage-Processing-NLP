{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "# setwd()\n",
    "\n",
    "# Needed for OutOfMemoryError: Java heap space \n",
    "library(rJava)\n",
    ".jinit(parameters=\"-Xmx4g\")\n",
    "# If there are more memory problems, invoke gc() after the POS tagging\n",
    "\n",
    "# The openNLPmodels.en library is not in CRAN; it has to be installed from another repository\n",
    "#install.packages(\"openNLPmodels.en\", repos = \"http://datacube.wu.ac.at\")\n",
    "\n",
    "library(NLP)\n",
    "library(openNLP) \n",
    "library(openNLPmodels.en)\n",
    "library(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns annotations for the text document: word, sentence, part-of-speech, and Penn Treebank parse annotations\n",
    "\n",
    "getAnnotationsFromDocument = function(doc){\n",
    "  x=as.String(doc)\n",
    "  sent_token_annotator <- Maxent_Sent_Token_Annotator()\n",
    "  word_token_annotator <- Maxent_Word_Token_Annotator()\n",
    "  pos_tag_annotator <- Maxent_POS_Tag_Annotator()\n",
    "  y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))\n",
    "  y2 <- annotate(x, pos_tag_annotator, y1)\n",
    "  parse_annotator <- Parse_Annotator()\n",
    "  y3 <- annotate(x, parse_annotator, y2)\n",
    "  return(y3)  \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the text document merged with the annotations\n",
    "\n",
    "getAnnotatedMergedDocument = function(doc,annotations){\n",
    "  x=as.String(doc)\n",
    "  y2w <- subset(annotations, type == \"word\")\n",
    "  tags <- sapply(y2w$features, '[[', \"POS\")\n",
    "  r1 <- sprintf(\"%s/%s\", x[y2w], tags)\n",
    "  r2 <- paste(r1, collapse = \" \")\n",
    "  return(r2)  \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the text document along with its annotations in an AnnotatedPlainTextDocument\n",
    "\n",
    "getAnnotatedPlainTextDocument = function(doc,annotations){\n",
    "  x=as.String(doc)\n",
    "  a = AnnotatedPlainTextDocument(x,annotations)\n",
    "  return(a)  \n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the corpus , we just take a small subset of 15 docs\n",
    "\n",
    "source.pos = DirSource(\"txt_sentoken/pos/smallSet\", encoding = \"UTF-8\")\n",
    "corpus = Corpus(source.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the getAnnotationsFromDocument function to every document in the corpus using lapply\n",
    "\n",
    "annotations = lapply(corpus, getAnnotationsFromDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<AnnotatedPlainTextDocument>>\n",
       "Metadata:  0\n",
       "Annotations:  length: 849\n",
       "Content:  chars: 4226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can create AnnotatedPlainTextDocuments that attach the annotations to the document and store the annotated corpus in another variable \n",
    "# (since we destroy the corpus metadata).\n",
    "\n",
    "corpus.tagged = Map(getAnnotatedPlainTextDocument, corpus, annotations)\n",
    "corpus.tagged[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<AnnotatedPlainTextDocument>>\n",
       "Metadata:  0\n",
       "Annotations:  length: 849\n",
       "Content:  chars: 4226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are functions for accessing parts of an AnnotatedPlainTextDocument.\n",
    "\n",
    "doc = corpus.tagged[[1]] \n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'to'</li>\n",
       "\t<li>'say'</li>\n",
       "\t<li>'moore'</li>\n",
       "\t<li>'and'</li>\n",
       "\t<li>'campbell'</li>\n",
       "\t<li>'thoroughly'</li>\n",
       "\t<li>'researched'</li>\n",
       "\t<li>'the'</li>\n",
       "\t<li>'subject'</li>\n",
       "\t<li>'of'</li>\n",
       "\t<li>'jack'</li>\n",
       "\t<li>'the'</li>\n",
       "\t<li>'ripper'</li>\n",
       "\t<li>'would'</li>\n",
       "\t<li>'be'</li>\n",
       "\t<li>'like'</li>\n",
       "\t<li>'saying'</li>\n",
       "\t<li>'michael'</li>\n",
       "\t<li>'jackson'</li>\n",
       "\t<li>'is'</li>\n",
       "\t<li>'starting'</li>\n",
       "\t<li>'to'</li>\n",
       "\t<li>'look'</li>\n",
       "\t<li>'a'</li>\n",
       "\t<li>'little'</li>\n",
       "\t<li>'odd'</li>\n",
       "\t<li>'.'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'to'\n",
       "\\item 'say'\n",
       "\\item 'moore'\n",
       "\\item 'and'\n",
       "\\item 'campbell'\n",
       "\\item 'thoroughly'\n",
       "\\item 'researched'\n",
       "\\item 'the'\n",
       "\\item 'subject'\n",
       "\\item 'of'\n",
       "\\item 'jack'\n",
       "\\item 'the'\n",
       "\\item 'ripper'\n",
       "\\item 'would'\n",
       "\\item 'be'\n",
       "\\item 'like'\n",
       "\\item 'saying'\n",
       "\\item 'michael'\n",
       "\\item 'jackson'\n",
       "\\item 'is'\n",
       "\\item 'starting'\n",
       "\\item 'to'\n",
       "\\item 'look'\n",
       "\\item 'a'\n",
       "\\item 'little'\n",
       "\\item 'odd'\n",
       "\\item '.'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'to'\n",
       "2. 'say'\n",
       "3. 'moore'\n",
       "4. 'and'\n",
       "5. 'campbell'\n",
       "6. 'thoroughly'\n",
       "7. 'researched'\n",
       "8. 'the'\n",
       "9. 'subject'\n",
       "10. 'of'\n",
       "11. 'jack'\n",
       "12. 'the'\n",
       "13. 'ripper'\n",
       "14. 'would'\n",
       "15. 'be'\n",
       "16. 'like'\n",
       "17. 'saying'\n",
       "18. 'michael'\n",
       "19. 'jackson'\n",
       "20. 'is'\n",
       "21. 'starting'\n",
       "22. 'to'\n",
       "23. 'look'\n",
       "24. 'a'\n",
       "25. 'little'\n",
       "26. 'odd'\n",
       "27. '.'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"to\"         \"say\"        \"moore\"      \"and\"        \"campbell\"  \n",
       " [6] \"thoroughly\" \"researched\" \"the\"        \"subject\"    \"of\"        \n",
       "[11] \"jack\"       \"the\"        \"ripper\"     \"would\"      \"be\"        \n",
       "[16] \"like\"       \"saying\"     \"michael\"    \"jackson\"    \"is\"        \n",
       "[21] \"starting\"   \"to\"         \"look\"       \"a\"          \"little\"    \n",
       "[26] \"odd\"        \".\"         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'if'</li>\n",
       "\t<li>'you'</li>\n",
       "\t<li>'can'</li>\n",
       "\t<li>'get'</li>\n",
       "\t<li>'past'</li>\n",
       "\t<li>'the'</li>\n",
       "\t<li>'whole'</li>\n",
       "\t<li>'comic'</li>\n",
       "\t<li>'book'</li>\n",
       "\t<li>'thing'</li>\n",
       "\t<li>','</li>\n",
       "\t<li>'you'</li>\n",
       "\t<li>'might'</li>\n",
       "\t<li>'find'</li>\n",
       "\t<li>'another'</li>\n",
       "\t<li>'stumbling'</li>\n",
       "\t<li>'block'</li>\n",
       "\t<li>'in'</li>\n",
       "\t<li>'from'</li>\n",
       "\t<li>'hell'</li>\n",
       "\t<li>'\\'s'</li>\n",
       "\t<li>'directors'</li>\n",
       "\t<li>','</li>\n",
       "\t<li>'albert'</li>\n",
       "\t<li>'and'</li>\n",
       "\t<li>'allen'</li>\n",
       "\t<li>'hughes'</li>\n",
       "\t<li>'.'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'if'\n",
       "\\item 'you'\n",
       "\\item 'can'\n",
       "\\item 'get'\n",
       "\\item 'past'\n",
       "\\item 'the'\n",
       "\\item 'whole'\n",
       "\\item 'comic'\n",
       "\\item 'book'\n",
       "\\item 'thing'\n",
       "\\item ','\n",
       "\\item 'you'\n",
       "\\item 'might'\n",
       "\\item 'find'\n",
       "\\item 'another'\n",
       "\\item 'stumbling'\n",
       "\\item 'block'\n",
       "\\item 'in'\n",
       "\\item 'from'\n",
       "\\item 'hell'\n",
       "\\item '\\textbackslash{}'s'\n",
       "\\item 'directors'\n",
       "\\item ','\n",
       "\\item 'albert'\n",
       "\\item 'and'\n",
       "\\item 'allen'\n",
       "\\item 'hughes'\n",
       "\\item '.'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'if'\n",
       "2. 'you'\n",
       "3. 'can'\n",
       "4. 'get'\n",
       "5. 'past'\n",
       "6. 'the'\n",
       "7. 'whole'\n",
       "8. 'comic'\n",
       "9. 'book'\n",
       "10. 'thing'\n",
       "11. ','\n",
       "12. 'you'\n",
       "13. 'might'\n",
       "14. 'find'\n",
       "15. 'another'\n",
       "16. 'stumbling'\n",
       "17. 'block'\n",
       "18. 'in'\n",
       "19. 'from'\n",
       "20. 'hell'\n",
       "21. '\\'s'\n",
       "22. 'directors'\n",
       "23. ','\n",
       "24. 'albert'\n",
       "25. 'and'\n",
       "26. 'allen'\n",
       "27. 'hughes'\n",
       "28. '.'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"if\"        \"you\"       \"can\"       \"get\"       \"past\"      \"the\"      \n",
       " [7] \"whole\"     \"comic\"     \"book\"      \"thing\"     \",\"         \"you\"      \n",
       "[13] \"might\"     \"find\"      \"another\"   \"stumbling\" \"block\"     \"in\"       \n",
       "[19] \"from\"      \"hell\"      \"'s\"        \"directors\" \",\"         \"albert\"   \n",
       "[25] \"and\"       \"allen\"     \"hughes\"    \".\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The two sentences chosen are:\n",
    "sents(doc)[[3]]\n",
    "sents(doc)[[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to/TO\n",
       "say/VB\n",
       "moore/NN\n",
       "and/CC\n",
       "campbell/NN\n",
       "thoroughly/RB\n",
       "researched/VBD\n",
       "the/DT\n",
       "subject/NN\n",
       "of/IN\n",
       "jack/NN\n",
       "the/DT\n",
       "ripper/NN\n",
       "would/MD\n",
       "be/VB\n",
       "like/IN\n",
       "saying/VBG\n",
       "michael/NN\n",
       "jackson/NN\n",
       "is/VBZ\n",
       "starting/VBG\n",
       "to/TO\n",
       "look/VB\n",
       "a/DT\n",
       "little/JJ\n",
       "odd/JJ\n",
       "./."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "if/IN\n",
       "you/PRP\n",
       "can/MD\n",
       "get/VB\n",
       "past/IN\n",
       "the/DT\n",
       "whole/JJ\n",
       "comic/JJ\n",
       "book/NN\n",
       "thing/NN\n",
       ",/,\n",
       "you/PRP\n",
       "might/MD\n",
       "find/VB\n",
       "another/DT\n",
       "stumbling/JJ\n",
       "block/NN\n",
       "in/IN\n",
       "from/IN\n",
       "hell/NN\n",
       "'s/POS\n",
       "directors/NNS\n",
       ",/,\n",
       "albert/NN\n",
       "and/CC\n",
       "allen/JJ\n",
       "hughes/NNS\n",
       "./."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Its taggs are:\n",
    "tagged_sents(doc)[[3]]\n",
    "tagged_sents(doc)[[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we go word by word applying \"The Penn Treebank\" tagset:\n",
    "\n",
    "### First sentence:\n",
    "\n",
    "* to —> TO\n",
    "* say —> VB \n",
    "* moore -> NN\n",
    "* and/CC —> CC\n",
    "* campbell -> NN\n",
    "* thoroughly -> RB\n",
    "* researched -> VBD\n",
    "* the -> DT\n",
    "* subject -> NN\n",
    "* of -> IN\n",
    "* jack -> NN\n",
    "* the -> DT\n",
    "* ripper -> NN\n",
    "* would -> MD\n",
    "* be -> VB\n",
    "* like -> IN\n",
    "* saying -> VBG\n",
    "* michael -> NN\n",
    "* jackson -> NN\n",
    "* is -> VBZ\n",
    "* starting ->VBG\n",
    "* to -> TO\n",
    "* look -> VB\n",
    "* a -> DT\n",
    "* little/JJ\n",
    "* odd -> JJ\n",
    "* . -> .\n",
    "\n",
    "#### Mistakes: 0, Accuracy: 100%\n",
    "\n",
    "### Second sentence:\n",
    "\n",
    "* if —> IN\n",
    "* you -> PRP\n",
    "* can -> MD\n",
    "* get -> VB\n",
    "* past -> IN\n",
    "* the -> DT\n",
    "* whole -> JJ\n",
    "* comic -> NN\n",
    "* book -> NN\n",
    "* thing -> NN\n",
    "* , -> ,\n",
    "* you -> PRP\n",
    "* might -> MD\n",
    "* find -> VB\n",
    "* another -> DT\n",
    "* stumbling -> JJ\n",
    "* block -> NN\n",
    "* in -> IN\n",
    "* from -> IN\n",
    "* hell -> NN\n",
    "* ’s -> POS\n",
    "* directors -> NNS\n",
    "* , -> ,\n",
    "* albert -> NN\n",
    "* and -> CC\n",
    "* allen —> NN\n",
    "* hughes -> NN\n",
    "* . -> .\n",
    "\n",
    "#### Mistakes: 3, Accuracy: 25 out of 28: 89'28%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
